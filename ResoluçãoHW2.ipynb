{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NBittent/FIAP_IA_MACHINE_LEARNING/blob/main/Resolu%C3%A7%C3%A3oHW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](images\\fiap_header_google_colab.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> * __Disciplina: Artificial Intelligence & Machine Learning__\n",
        "* Nícolas Miguel Bittencourt Tanajura:\n",
        "  * [Linkedin](https://www.linkedin.com/in/nicolas-tanajura/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU2rPjAXPpgn"
      },
      "source": [
        "Este notebook tem como objetivo realizar uma análise descritiva de um conjunto de dados de URLs para identificar padrões relacionados a phishing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnij3wNdP7cc"
      },
      "source": [
        "#### Resolução Homework - RM554045 - Nícolas Tanajura:\n",
        "\n",
        "\n",
        "3 Variáveis que serão analisadas\n",
        "\n",
        "\n",
        "1. **UrlLength**\n",
        "\n",
        "URLs de phishing costumam ser muito longas, tentando confundir o usuário, inserindo palavras-chave ou subdomínios falsos para parecerem legítimas. Analisar o\n",
        "comprimento total é uma métrica importante para identificar esse comportamento.\n",
        "\n",
        "\n",
        "2. **SubdomainLevel**\n",
        "\n",
        "\n",
        "Phishers frequentemente usam subdomínios adicionais para mascarar o domínio\n",
        "real, tentando enganar as vítimas. Por exemplo, \"seguro.banco.falso.com\" pode ser\n",
        "usado para simular legitimidade.\n",
        "\n",
        "\n",
        "3. **PctExtHyperlinks**\n",
        "\n",
        "\n",
        "Páginas de phishing tendem a ter muitos hiperlinks externos, levando o usuário para\n",
        "sites controlados pelos atacantes. Analisar a proporção de links externos em relação\n",
        "aos internos ajuda a identificar comportamentos suspeitos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Média UrlLength\n",
        "mean_value_url_length = df['UrlLength'].mean()\n",
        "mean_value_url_length_legitimas = df[df['CLASS_LABEL'] == 0]['UrlLength'].mean()\n",
        "mean_value_url_length_phishing = df[df['CLASS_LABEL'] == 1]['UrlLength'].mean()\n",
        "\n",
        "# Média SubdomainLevel\n",
        "mean_value_subdomain_level = df['SubdomainLevel'].mean()\n",
        "mean_value_subdomain_level_legitimas = df[df['CLASS_LABEL'] == 0]['SubdomainLevel'].mean()\n",
        "mean_value_subdomain_level_phishing = df[df['CLASS_LABEL'] == 1]['SubdomainLevel'].mean()\n",
        "\n",
        "# Média PctExtHyperlinks\n",
        "mean_value_pct_ext_hyperlinks = df['PctExtHyperlinks'].mean()\n",
        "mean_value_pct_ext_hyperlinks_legitimas = df[df['CLASS_LABEL'] == 0]['PctExtHyperlinks'].mean()\n",
        "mean_value_pct_ext_hyperlinks_phishing = df[df['CLASS_LABEL'] == 1]['PctExtHyperlinks'].mean()\n",
        "\n",
        "# Mediana UrlLength\n",
        "median_value_url_length = df['UrlLength'].median()\n",
        "median_value_url_length_legitimas = df[df['CLASS_LABEL'] == 0]['UrlLength'].median()\n",
        "median_value_url_length_phishing = df[df['CLASS_LABEL'] == 1]['UrlLength'].median()\n",
        "\n",
        "# Mediana SubdomainLevel\n",
        "median_value_subdomain_level = df['SubdomainLevel'].median()\n",
        "median_value_subdomain_level_legitimas = df[df['CLASS_LABEL'] == 0]['SubdomainLevel'].median()\n",
        "median_value_subdomain_level_phishing = df[df['CLASS_LABEL'] == 1]['SubdomainLevel'].median()\n",
        "\n",
        "# Mediana PctExtHyperlinks\n",
        "median_value_pct_ext_hyperlinks = df['PctExtHyperlinks'].median()\n",
        "median_value_pct_ext_hyperlinks_legitimas = df[df['CLASS_LABEL'] == 0]['PctExtHyperlinks'].median()\n",
        "median_value_pct_ext_hyperlinks_phishing = df[df['CLASS_LABEL'] == 1]['PctExtHyperlinks'].median()\n",
        "\n",
        "# Exibir os resultados\n",
        "print(\"Média UrlLength (Todas):\", mean_value_url_length)\n",
        "print(\"Média UrlLength (Legitimas):\", mean_value_url_length_legitimas)\n",
        "print(\"Média UrlLength (Phishing):\", mean_value_url_length_phishing)\n",
        "\n",
        "print(\"\\nMédia SubdomainLevel (Todas):\", mean_value_subdomain_level)\n",
        "print(\"Média SubdomainLevel (Legitimas):\", mean_value_subdomain_level_legitimas)\n",
        "print(\"Média SubdomainLevel (Phishing):\", mean_value_subdomain_level_phishing)\n",
        "\n",
        "print(\"\\nMédia PctExtHyperlinks (Todas):\", mean_value_pct_ext_hyperlinks)\n",
        "print(\"Média PctExtHyperlinks (Legitimas):\", mean_value_pct_ext_hyperlinks_legitimas)\n",
        "print(\"Média PctExtHyperlinks (Phishing):\", mean_value_pct_ext_hyperlinks_phishing)\n",
        "\n",
        "print(\"\\nMediana UrlLength (Todas):\", median_value_url_length)\n",
        "print(\"Mediana UrlLength (Legitimas):\", median_value_url_length_legitimas)\n",
        "print(\"Mediana UrlLength (Phishing):\", median_value_url_length_phishing)\n",
        "\n",
        "print(\"\\nMediana SubdomainLevel (Todas):\", median_value_subdomain_level)\n",
        "print(\"Mediana SubdomainLevel (Legitimas):\", median_value_subdomain_level_legitimas)\n",
        "print(\"Mediana SubdomainLevel (Phishing):\", median_value_subdomain_level_phishing)\n",
        "\n",
        "print(\"\\nMediana PctExtHyperlinks (Todas):\", median_value_pct_ext_hyperlinks)\n",
        "print(\"Mediana PctExtHyperlinks (Legitimas):\", median_value_pct_ext_hyperlinks_legitimas)\n",
        "print(\"Mediana PctExtHyperlinks (Phishing):\", median_value_pct_ext_hyperlinks_phishing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L-Fj6RrQD26"
      },
      "source": [
        "### Conclusão do Homework 1:\n",
        "As variáveis escolhidas mostraram diferenças significativas entre URLs legítimas e de phishing. A análise das médias e medianas sugere que essas características são indicadores úteis na identificação de phishing, com URLs de phishing tendendo a ser mais curtas, mas contendo mais subdomínios e links externos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Homework 2:\n",
        "\n",
        "1. **Introdução**\n",
        "\n",
        "Este notebook tem como objetivo determinar qual das duas bases de dados (`phishing_base_X.csv` ou `phishing_base_Y.csv`) possui a maior probabilidade de conter URLs de phishing. A análise será feita com base em três variáveis-chave observadas em `urls_phishing.csv`: `Length of URL`, `Depth of URL`, e `DNS Record`.\n",
        "\n",
        "*Observação: Duas variáveis do exercício anterior não estão presentes nos novos banco de dados.*\n",
        "\n",
        "2. **Carregamento e Preparação dos Dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# URL dos arquivos CSV no GitHub\n",
        "url_phishing = r'datasets\\urls_phishing.csv'\n",
        "url_base_X = r'datasets\\phishing_base_X.csv'\n",
        "url_base_Y = r'datasets\\phishing_base_Y.csv'\n",
        "\n",
        "# Carregar os arquivos CSV em DataFrames\n",
        "df_phishing = pd.read_csv(url_phishing, delimiter=',', encoding='utf-8')\n",
        "df_base_X = pd.read_csv(url_base_X, delimiter=',', encoding='utf-8')\n",
        "df_base_Y = pd.read_csv(url_base_Y, delimiter=',', encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. **Analisar Padrões de Phishing (urls_phishing.csv)**\n",
        "\n",
        "\n",
        "Aqui, calculamos as estatísticas descritivas das três variáveis de interesse no dataset de phishing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Variância das URLs de phishing:\n",
            " Length of URL    3427.093491\n",
            "Depth of URL        3.850610\n",
            "DNS Record          0.068535\n",
            "dtype: float64\n",
            "\n",
            "Desvio Padrão das URLs de phishing:\n",
            " Length of URL    58.541383\n",
            "Depth of URL      1.962297\n",
            "DNS Record        0.261791\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Variáveis selecionadas\n",
        "variaveis = ['Length of URL', 'Depth of URL', 'DNS Record']\n",
        "\n",
        "# Calcular a variância e o desvio padrão diretamente\n",
        "var_phishing = df_phishing[variaveis].var()\n",
        "std_phishing = df_phishing[variaveis].std()\n",
        "\n",
        "# Exibir os resultados\n",
        "print(\"\\nVariância das URLs de phishing:\\n\", var_phishing)\n",
        "print(\"\\nDesvio Padrão das URLs de phishing:\\n\", std_phishing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. **Comparar Padrões com Bases X e Y**\n",
        "\n",
        "Comparar as mesmas variáveis nas bases phishing_base_X e phishing_base_Y com as estatísticas de phishing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Variância das URLs na Base X:\n",
            " Length of URL    2877.966394\n",
            "Depth of URL        1.629097\n",
            "DNS Record          0.060851\n",
            "dtype: float64\n",
            "\n",
            "Desvio Padrão das URLs na Base X:\n",
            " Length of URL    53.646681\n",
            "Depth of URL      1.276361\n",
            "DNS Record        0.246680\n",
            "dtype: float64\n",
            "\n",
            "Variância das URLs na Base Y:\n",
            " Length of URL    1842.807195\n",
            "Depth of URL        4.746533\n",
            "DNS Record          0.066256\n",
            "dtype: float64\n",
            "\n",
            "Desvio Padrão das URLs na Base Y:\n",
            " Length of URL    42.927930\n",
            "Depth of URL      2.178654\n",
            "DNS Record        0.257403\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Calcular a variância e o desvio padrão para a Base X\n",
        "var_base_X = df_base_X[variaveis].var()\n",
        "std_base_X = df_base_X[variaveis].std()\n",
        "\n",
        "# Exibir os resultados para a Base X\n",
        "print(\"\\nVariância das URLs na Base X:\\n\", var_base_X)\n",
        "print(\"\\nDesvio Padrão das URLs na Base X:\\n\", std_base_X)\n",
        "\n",
        "# Calcular a variância e o desvio padrão para a Base Y\n",
        "var_base_Y = df_base_Y[variaveis].var()\n",
        "std_base_Y = df_base_Y[variaveis].std()\n",
        "\n",
        "# Exibir os resultados para a Base Y\n",
        "print(\"\\nVariância das URLs na Base Y:\\n\", var_base_Y)\n",
        "print(\"\\nDesvio Padrão das URLs na Base Y:\\n\", std_base_Y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. **Calcular Proximidade entre Bases e Phishing**\n",
        "\n",
        "Calcular a proximidade (por exemplo, distância absoluta entre as médias) para determinar qual base é mais próxima do padrão de phishing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distância total da Base X em relação ao padrão de phishing:\n",
            " 29.019615384615385\n",
            "\n",
            "Distância total da Base Y em relação ao padrão de phishing:\n",
            " 29.865884615384623\n"
          ]
        }
      ],
      "source": [
        "# Cálculo da distância entre as médias de phishing e das bases X e Y\n",
        "dist_X = abs(phishing_stats.loc['mean'] - base_X_stats.loc['mean'])\n",
        "dist_Y = abs(phishing_stats.loc['mean'] - base_Y_stats.loc['mean'])\n",
        "\n",
        "# Somar as distâncias para obter uma métrica geral\n",
        "dist_total_X = dist_X.sum()\n",
        "dist_total_Y = dist_Y.sum()\n",
        "\n",
        "print(\"\\nDistância total da Base X em relação ao padrão de phishing:\\n\", dist_total_X)\n",
        "print(\"\\nDistância total da Base Y em relação ao padrão de phishing:\\n\", dist_total_Y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusão:\n",
        "\n",
        "*Observação: Os calculos apresentados para a variável Length of URL ainda mostram dados muito importantes para a análise como na HW1.*\n",
        "\n",
        "Com base na análise, a Base X tem uma maior proximidade com os padrões observados em `urls_phishing.csv`, sugerindo que ela tem a maior probabilidade de conter URLs de phishing.\n",
        "\n",
        "Como eu tenho um conjunto de dados com rótulos, a abordagem mais prática e eficaz para analisar dados de phishing é começar com algoritmos supervisionados. Com esses algoritmos, posso treinar um modelo usando os exemplos rotulados que já tenho. Isso me permitirá criar um modelo capaz de identificar e classificar URLs como phishing ou não phishing com base nas características que já conhecemos. Assim, posso usar esses dados para desenvolver uma ferramenta mais eficiente na detecção de e-mails de phishing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Referências:\n",
        "\n",
        "- Repositório GitHub: [FIAP IA MACHINE LEARNING](https://github.com/NBittent/FIAP_IA_MACHINE_LEARNING)\n",
        "  - [urls_phishing.csv](https://github.com/NBittent/FIAP_IA_MACHINE_LEARNING/blob/main/urls_phishing.csv)\n",
        "  - [phishing_base_X.csv](https://github.com/NBittent/FIAP_IA_MACHINE_LEARNING/blob/main/phishing_base_X.csv)\n",
        "  - [phishing_base_Y.csv](https://github.com/NBittent/FIAP_IA_MACHINE_LEARNING/blob/main/phishing_base_Y.csv)\n",
        "- Pandas Documentation: https://pandas.pydata.org/\n",
        "- Kaggle Dataset: https://www.kaggle.com/datasets/shashwatwork/phishing-dataset-for-machine-learning\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPbUf2vcqXV0FkjyxLEP87C",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
